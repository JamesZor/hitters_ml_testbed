# Baseball Salary Prediction - MLOps Project

This project demonstrates MLOps best practices for a baseball salary prediction task using PyTorch, PyTorch Lightning, Weights & Biases, and Hydra.

## Features

- ğŸ”§ **Modular Architecture**: Separate modules for data, models, training, and utilities
- âš™ï¸ **Configuration Management**: Hydra-based configs for easy experimentation
- ğŸ“Š **Experiment Tracking**: Weights & Biases integration for experiment monitoring
- ğŸ—ï¸ **Multiple Model Architectures**: Simple NN, Deep NN, and Residual NN
- ğŸ”„ **Hyperparameter Optimization**: Automated hyperparameter sweeps
- ğŸ“ˆ **Comprehensive Evaluation**: Detailed model analysis and visualization
- ğŸ§ª **Reproducible**: Deterministic training with proper seed management

## Setup

1. **Create project structure:**
```bash
git clone <your-repo>
cd hitters_ml_project
```

2. **Install dependencies:**
```bash
pip install -r requirements.txt
# or
pip install -e .
```

3. **Setup Weights & Biases:**
```bash
wandb login
```

## Usage

### Basic Training

```bash
# Train with default configuration
python train.py

# Use different model
python train.py model=deep_nn

# Override parameters
python train.py model.learning_rate=0.01 training.max_epochs=100

# Disable wandb logging
python train.py wandb.mode=disabled
```

### Hyperparameter Sweeps

```bash
# Initialize sweep
wandb sweep sweep.yaml

# Run sweep agent
wandb agent <sweep-id>
```

### Model Evaluation

```bash
# Evaluate trained model
python evaluate.py experiments/2024-01-15_10-30-45/checkpoints/best-epoch=42-val_loss=0.123.ckpt --output_dir results/
```

### Advanced Usage

```bash
# Multi-run experiments
python train.py --multirun model=simple_nn,deep_nn model.learning_rate=0.001,0.01

# Experiment with different data configurations
python train.py data.batch_size=64 data.standardize=false

# Custom experiment naming
python train.py experiment.name="my_custom_experiment"
```

## Project Structure

```
â”œâ”€â”€ configs/          # Hydra configuration files
â”œâ”€â”€ src/             # Source code
â”‚   â”œâ”€â”€ data/        # Data loading and preprocessing
â”‚   â”œâ”€â”€ models/      # Model architectures
â”‚   â”œâ”€â”€ training/    # Training utilities
â”‚   â”œâ”€â”€ utils/       # General utilities
â”‚   â””â”€â”€ visualization/ # Plotting functions
â”œâ”€â”€ experiments/     # Saved experiment outputs
â”œâ”€â”€ models/         # Saved model checkpoints
â””â”€â”€ notebooks/      # Jupyter notebooks
```

## Configuration

The project uses Hydra for configuration management. Key configuration files:

- `configs/experiment.yaml`: Main experiment configuration
- `configs/model/`: Model architecture configurations
- `configs/data/`: Data loading configurations
- `configs/training/`: Training hyperparameters

## MLOps Features

- **Experiment Tracking**: All runs logged to Weights & Biases
- **Model Versioning**: Automatic model checkpointing and versioning
- **Reproducibility**: Deterministic training with seed management
- **Configuration Management**: Easy parameter tuning via YAML configs
- **Automated Evaluation**: Comprehensive model evaluation pipeline
- **Hyperparameter Optimization**: Bayesian optimization with W&B sweeps

## Results
